[10/11 06:54:43] detectron2 INFO: Rank of current process: 0. World size: 1
[10/11 06:54:43] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]
numpy                   1.23.5
detectron2              0.6 @/home/hoenig/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu116 @/home/hoenig/.local/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          525.125.06
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.13.0+cu116 @/home/hoenig/.local/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.3.0
----------------------  -------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 06:54:43] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/11 06:54:43] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./mvit2_itodd_with_aug_output/config.yaml is human-readable but cannot be loaded.
[10/11 06:54:43] d2.config.lazy WARNING: Config is saved using cloudpickle at ./mvit2_itodd_with_aug_output/config.yaml.pkl.
[10/11 06:54:43] detectron2 INFO: Full config saved to ./mvit2_itodd_with_aug_output/config.yaml
[10/11 06:54:43] d2.utils.env INFO: Using a generated random seed 44116768
[10/11 06:57:44] detectron2 INFO: Rank of current process: 0. World size: 1
[10/11 06:57:44] detectron2 INFO: Environment info:
----------------------  -------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]
numpy                   1.23.5
detectron2              0.6 @/home/hoenig/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.0+cu116 @/home/hoenig/.local/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          525.125.06
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.13.0+cu116 @/home/hoenig/.local/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.3.0
----------------------  -------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/11 06:57:44] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[10/11 06:57:44] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./mvit2_itodd_with_aug_output/config.yaml is human-readable but cannot be loaded.
[10/11 06:57:44] d2.config.lazy WARNING: Config is saved using cloudpickle at ./mvit2_itodd_with_aug_output/config.yaml.pkl.
[10/11 06:57:44] detectron2 INFO: Full config saved to ./mvit2_itodd_with_aug_output/config.yaml
[10/11 06:57:44] d2.utils.env INFO: Using a generated random seed 45301865
[10/11 06:57:45] d2.evaluation.coco_evaluation INFO: Trying to convert 'itodd_bop_val' to COCO format ...
[10/11 06:57:45] d2.data.datasets.coco INFO: Converting annotations of dataset 'itodd_bop_val' to COCO format ...)
[10/11 06:57:45] d2.data.datasets.coco INFO: Converting dataset dicts into COCO format
[10/11 06:57:45] d2.data.datasets.coco INFO: Conversion finished, #images: 54, #annotations: 123
[10/11 06:57:45] d2.data.datasets.coco INFO: Caching COCO format annotations at './mvit2_itodd_with_aug_output/itodd_bop_val_coco_format.json' ...
[10/11 06:57:45] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): MViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=96, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.013)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=96, out_features=192, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.027)
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (3): MultiScaleBlock(
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=192, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.040)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=192, out_features=384, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (4): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.053)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.067)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (6): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.080)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (7): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.093)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.107)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (9): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.120)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (10): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.133)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (11): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.147)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (12): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.160)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (13): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.173)
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (14): MultiScaleBlock(
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=384, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.187)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (proj): Linear(in_features=384, out_features=768, bias=True)
          (pool_skip): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        )
        (15): MultiScaleBlock(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (pool_q): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_k): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (pool_v): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          )
          (drop_path): DropPath(drop_prob=0.200)
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (scale2_norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (scale3_norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (scale4_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (scale5_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): ReLU()
        )
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=29, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=29, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=29, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[10/11 06:57:59] d2.data.datasets.coco INFO: Loading datasets/BOP_DATASETS/itodd/itodd_annotations_train.json takes 12.61 seconds.
[10/11 06:57:59] d2.data.datasets.coco INFO: Loaded 50000 images in COCO format from datasets/BOP_DATASETS/itodd/itodd_annotations_train.json
[10/11 06:58:03] d2.data.build INFO: Removed 1 images with no usable annotations. 49999 images left.
[10/11 06:58:04] d2.data.build INFO: Distribution of instances among all 28 categories:
[36m|  category  | #instances   | category   | #instances   | category   | #instances   |
|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|
|     1      | 20604        | 2          | 18371        | 3          | 25679        |
|     4      | 24857        | 5          | 24607        | 6          | 20818        |
|     7      | 17738        | 8          | 20760        | 9          | 23939        |
|     10     | 18639        | 11         | 24645        | 12         | 23827        |
|     13     | 25377        | 14         | 23770        | 15         | 23344        |
|     16     | 27587        | 17         | 21965        | 18         | 23681        |
|     19     | 20883        | 20         | 22779        | 21         | 26272        |
|     22     | 26403        | 23         | 17417        | 24         | 20237        |
|     25     | 18236        | 26         | 21009        | 27         | 19434        |
|     28     | 14986        |            |              |            |              |
|   total    | 617864       |            |              |            |              |[0m
[10/11 06:58:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: []
[10/11 06:58:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[10/11 06:58:04] d2.data.common INFO: Serializing 49999 elements to byte tensors and concatenating them all ...
[10/11 06:58:07] d2.data.common INFO: Serialized dataset takes 565.41 MiB
[10/11 06:58:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/mvitv2/MViTv2_S_in1k.pyth ...
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv1.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv1.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv2.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv2.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv3.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv3.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv4.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.0.conv4.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv1.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv1.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv2.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv2.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv3.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv3.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv4.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.1.conv4.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv1.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv1.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv2.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv2.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv3.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv3.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv4.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.2.conv4.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.bias in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.weight in model is torch.Size([256]).
[10/11 06:58:09] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[10/11 06:58:10] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model      | Names in Checkpoint                                                                                                                                                                                    | Shapes                                                                                                                   |
|:--------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------|
| blocks.0.attn.*     | blocks.0.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (96,) (96,96) (288,) (288,96) (111,96) (111,96)     |
| blocks.0.mlp.fc1.*  | blocks.0.mlp.fc1.{bias,weight}                                                                                                                                                                         | (384,) (384,96)                                                                                                          |
| blocks.0.mlp.fc2.*  | blocks.0.mlp.fc2.{bias,weight}                                                                                                                                                                         | (96,) (96,384)                                                                                                           |
| blocks.0.norm1.*    | blocks.0.norm1.{bias,weight}                                                                                                                                                                           | (96,) (96,)                                                                                                              |
| blocks.0.norm2.*    | blocks.0.norm2.{bias,weight}                                                                                                                                                                           | (96,) (96,)                                                                                                              |
| blocks.1.attn.*     | blocks.1.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (192,) (192,192) (576,) (576,96) (55,96) (55,96)    |
| blocks.1.mlp.fc1.*  | blocks.1.mlp.fc1.{bias,weight}                                                                                                                                                                         | (768,) (768,192)                                                                                                         |
| blocks.1.mlp.fc2.*  | blocks.1.mlp.fc2.{bias,weight}                                                                                                                                                                         | (192,) (192,768)                                                                                                         |
| blocks.1.norm1.*    | blocks.1.norm1.{bias,weight}                                                                                                                                                                           | (96,) (96,)                                                                                                              |
| blocks.1.norm2.*    | blocks.1.norm2.{bias,weight}                                                                                                                                                                           | (192,) (192,)                                                                                                            |
| blocks.1.proj.*     | blocks.1.proj.{bias,weight}                                                                                                                                                                            | (192,) (192,96)                                                                                                          |
| blocks.10.attn.*    | blocks.10.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.10.mlp.fc1.* | blocks.10.mlp.fc1.{bias,weight}                                                                                                                                                                        | (1536,) (1536,384)                                                                                                       |
| blocks.10.mlp.fc2.* | blocks.10.mlp.fc2.{bias,weight}                                                                                                                                                                        | (384,) (384,1536)                                                                                                        |
| blocks.10.norm1.*   | blocks.10.norm1.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.10.norm2.*   | blocks.10.norm2.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.11.attn.*    | blocks.11.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.11.mlp.fc1.* | blocks.11.mlp.fc1.{bias,weight}                                                                                                                                                                        | (1536,) (1536,384)                                                                                                       |
| blocks.11.mlp.fc2.* | blocks.11.mlp.fc2.{bias,weight}                                                                                                                                                                        | (384,) (384,1536)                                                                                                        |
| blocks.11.norm1.*   | blocks.11.norm1.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.11.norm2.*   | blocks.11.norm2.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.12.attn.*    | blocks.12.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.12.mlp.fc1.* | blocks.12.mlp.fc1.{bias,weight}                                                                                                                                                                        | (1536,) (1536,384)                                                                                                       |
| blocks.12.mlp.fc2.* | blocks.12.mlp.fc2.{bias,weight}                                                                                                                                                                        | (384,) (384,1536)                                                                                                        |
| blocks.12.norm1.*   | blocks.12.norm1.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.12.norm2.*   | blocks.12.norm2.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.13.attn.*    | blocks.13.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.13.mlp.fc1.* | blocks.13.mlp.fc1.{bias,weight}                                                                                                                                                                        | (1536,) (1536,384)                                                                                                       |
| blocks.13.mlp.fc2.* | blocks.13.mlp.fc2.{bias,weight}                                                                                                                                                                        | (384,) (384,1536)                                                                                                        |
| blocks.13.norm1.*   | blocks.13.norm1.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.13.norm2.*   | blocks.13.norm2.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.14.attn.*    | blocks.14.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (768,) (768,768) (2304,) (2304,384) (27,96) (27,96) |
| blocks.14.mlp.fc1.* | blocks.14.mlp.fc1.{bias,weight}                                                                                                                                                                        | (3072,) (3072,768)                                                                                                       |
| blocks.14.mlp.fc2.* | blocks.14.mlp.fc2.{bias,weight}                                                                                                                                                                        | (768,) (768,3072)                                                                                                        |
| blocks.14.norm1.*   | blocks.14.norm1.{bias,weight}                                                                                                                                                                          | (384,) (384,)                                                                                                            |
| blocks.14.norm2.*   | blocks.14.norm2.{bias,weight}                                                                                                                                                                          | (768,) (768,)                                                                                                            |
| blocks.14.proj.*    | blocks.14.proj.{bias,weight}                                                                                                                                                                           | (768,) (768,384)                                                                                                         |
| blocks.15.attn.*    | blocks.15.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w} | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (768,) (768,768) (2304,) (2304,768) (13,96) (13,96) |
| blocks.15.mlp.fc1.* | blocks.15.mlp.fc1.{bias,weight}                                                                                                                                                                        | (3072,) (3072,768)                                                                                                       |
| blocks.15.mlp.fc2.* | blocks.15.mlp.fc2.{bias,weight}                                                                                                                                                                        | (768,) (768,3072)                                                                                                        |
| blocks.15.norm1.*   | blocks.15.norm1.{bias,weight}                                                                                                                                                                          | (768,) (768,)                                                                                                            |
| blocks.15.norm2.*   | blocks.15.norm2.{bias,weight}                                                                                                                                                                          | (768,) (768,)                                                                                                            |
| blocks.2.attn.*     | blocks.2.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (192,) (192,192) (576,) (576,192) (55,96) (55,96)   |
| blocks.2.mlp.fc1.*  | blocks.2.mlp.fc1.{bias,weight}                                                                                                                                                                         | (768,) (768,192)                                                                                                         |
| blocks.2.mlp.fc2.*  | blocks.2.mlp.fc2.{bias,weight}                                                                                                                                                                         | (192,) (192,768)                                                                                                         |
| blocks.2.norm1.*    | blocks.2.norm1.{bias,weight}                                                                                                                                                                           | (192,) (192,)                                                                                                            |
| blocks.2.norm2.*    | blocks.2.norm2.{bias,weight}                                                                                                                                                                           | (192,) (192,)                                                                                                            |
| blocks.3.attn.*     | blocks.3.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,192) (55,96) (55,96) |
| blocks.3.mlp.fc1.*  | blocks.3.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.3.mlp.fc2.*  | blocks.3.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.3.norm1.*    | blocks.3.norm1.{bias,weight}                                                                                                                                                                           | (192,) (192,)                                                                                                            |
| blocks.3.norm2.*    | blocks.3.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.3.proj.*     | blocks.3.proj.{bias,weight}                                                                                                                                                                            | (384,) (384,192)                                                                                                         |
| blocks.4.attn.*     | blocks.4.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.4.mlp.fc1.*  | blocks.4.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.4.mlp.fc2.*  | blocks.4.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.4.norm1.*    | blocks.4.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.4.norm2.*    | blocks.4.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.5.attn.*     | blocks.5.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.5.mlp.fc1.*  | blocks.5.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.5.mlp.fc2.*  | blocks.5.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.5.norm1.*    | blocks.5.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.5.norm2.*    | blocks.5.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.6.attn.*     | blocks.6.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.6.mlp.fc1.*  | blocks.6.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.6.mlp.fc2.*  | blocks.6.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.6.norm1.*    | blocks.6.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.6.norm2.*    | blocks.6.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.7.attn.*     | blocks.7.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.7.mlp.fc1.*  | blocks.7.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.7.mlp.fc2.*  | blocks.7.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.7.norm1.*    | blocks.7.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.7.norm2.*    | blocks.7.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.8.attn.*     | blocks.8.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.8.mlp.fc1.*  | blocks.8.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.8.mlp.fc2.*  | blocks.8.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.8.norm1.*    | blocks.8.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.8.norm2.*    | blocks.8.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.9.attn.*     | blocks.9.attn.{norm_k.bias,norm_k.weight,norm_q.bias,norm_q.weight,norm_v.bias,norm_v.weight,pool_k.weight,pool_q.weight,pool_v.weight,proj.bias,proj.weight,qkv.bias,qkv.weight,rel_pos_h,rel_pos_w}  | (96,) (96,) (96,) (96,) (96,) (96,) (96,1,3,3) (96,1,3,3) (96,1,3,3) (384,) (384,384) (1152,) (1152,384) (27,96) (27,96) |
| blocks.9.mlp.fc1.*  | blocks.9.mlp.fc1.{bias,weight}                                                                                                                                                                         | (1536,) (1536,384)                                                                                                       |
| blocks.9.mlp.fc2.*  | blocks.9.mlp.fc2.{bias,weight}                                                                                                                                                                         | (384,) (384,1536)                                                                                                        |
| blocks.9.norm1.*    | blocks.9.norm1.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| blocks.9.norm2.*    | blocks.9.norm2.{bias,weight}                                                                                                                                                                           | (384,) (384,)                                                                                                            |
| patch_embed.proj.*  | patch_embed.proj.{bias,weight}                                                                                                                                                                         | (96,) (96,3,7,7)                                                                                                         |
[10/11 06:58:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.bottom_up.scale2_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale3_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale4_norm.{bias, weight}[0m
[34mbackbone.bottom_up.scale5_norm.{bias, weight}[0m
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.0.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv1.weight[0m
[34mroi_heads.box_head.0.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv2.weight[0m
[34mroi_heads.box_head.0.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv3.weight[0m
[34mroi_heads.box_head.0.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.0.conv4.weight[0m
[34mroi_heads.box_head.0.fc1.{bias, weight}[0m
[34mroi_heads.box_head.1.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv1.weight[0m
[34mroi_heads.box_head.1.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv2.weight[0m
[34mroi_heads.box_head.1.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv3.weight[0m
[34mroi_heads.box_head.1.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.1.conv4.weight[0m
[34mroi_heads.box_head.1.fc1.{bias, weight}[0m
[34mroi_heads.box_head.2.conv1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv1.weight[0m
[34mroi_heads.box_head.2.conv2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv2.weight[0m
[34mroi_heads.box_head.2.conv3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv3.weight[0m
[34mroi_heads.box_head.2.conv4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.box_head.2.conv4.weight[0m
[34mroi_heads.box_head.2.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.0.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.0.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.1.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.1.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.2.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.2.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.weight[0m
[34mroi_heads.mask_head.mask_fcn2.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.weight[0m
[34mroi_heads.mask_head.mask_fcn3.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.weight[0m
[34mroi_heads.mask_head.mask_fcn4.norm.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.weight[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[10/11 06:58:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mhead.projection.{bias, weight}[0m
  [35mnorm.{bias, weight}[0m
[10/11 06:58:10] d2.engine.train_loop INFO: Starting training from iteration 0
[10/11 06:58:31] d2.utils.events INFO:  eta: 5 days, 6:56:52  iter: 19  total_loss: 11.1  loss_cls_stage0: 3.276  loss_box_reg_stage0: 0.001267  loss_cls_stage1: 3.145  loss_box_reg_stage1: 0.003772  loss_cls_stage2: 3.108  loss_box_reg_stage2: 0.006925  loss_mask: 0.6931  loss_rpn_cls: 0.6981  loss_rpn_loc: 0.1492  time: 0.9128  data_time: 0.0116  lr: 1.8e-06  max_mem: 19178M
[10/11 06:58:49] d2.utils.events INFO:  eta: 5 days, 7:38:36  iter: 39  total_loss: 8.82  loss_cls_stage0: 2.52  loss_box_reg_stage0: 0.03101  loss_cls_stage1: 2.362  loss_box_reg_stage1: 0.01357  loss_cls_stage2: 2.304  loss_box_reg_stage2: 0.007961  loss_mask: 0.693  loss_rpn_cls: 0.6867  loss_rpn_loc: 0.151  time: 0.9239  data_time: 0.0045  lr: 3.5262e-06  max_mem: 19178M
[10/11 06:59:09] d2.utils.events INFO:  eta: 5 days, 9:50:36  iter: 59  total_loss: 5.542  loss_cls_stage0: 1.365  loss_box_reg_stage0: 0.2798  loss_cls_stage1: 1.143  loss_box_reg_stage1: 0.1335  loss_cls_stage2: 1.052  loss_box_reg_stage2: 0.03434  loss_mask: 0.6929  loss_rpn_cls: 0.6611  loss_rpn_loc: 0.1488  time: 0.9429  data_time: 0.0045  lr: 5.2525e-06  max_mem: 19489M
[10/11 06:59:29] d2.utils.events INFO:  eta: 5 days, 14:00:59  iter: 79  total_loss: 4.239  loss_cls_stage0: 0.9287  loss_box_reg_stage0: 0.5185  loss_cls_stage1: 0.5265  loss_box_reg_stage1: 0.2834  loss_cls_stage2: 0.3505  loss_box_reg_stage2: 0.09482  loss_mask: 0.6928  loss_rpn_cls: 0.6046  loss_rpn_loc: 0.1653  time: 0.9590  data_time: 0.0047  lr: 6.9788e-06  max_mem: 19900M
[10/11 06:59:49] d2.utils.events INFO:  eta: 5 days, 15:38:41  iter: 99  total_loss: 4.148  loss_cls_stage0: 0.9423  loss_box_reg_stage0: 0.581  loss_cls_stage1: 0.5219  loss_box_reg_stage1: 0.3237  loss_cls_stage2: 0.319  loss_box_reg_stage2: 0.107  loss_mask: 0.6925  loss_rpn_cls: 0.5063  loss_rpn_loc: 0.1555  time: 0.9699  data_time: 0.0050  lr: 8.705e-06  max_mem: 19991M
[10/11 07:00:10] d2.utils.events INFO:  eta: 5 days, 17:23:43  iter: 119  total_loss: 4.354  loss_cls_stage0: 1.021  loss_box_reg_stage0: 0.68  loss_cls_stage1: 0.5492  loss_box_reg_stage1: 0.3749  loss_cls_stage2: 0.318  loss_box_reg_stage2: 0.119  loss_mask: 0.6922  loss_rpn_cls: 0.3513  loss_rpn_loc: 0.1952  time: 0.9783  data_time: 0.0047  lr: 1.0431e-05  max_mem: 20031M
[10/11 07:00:13] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/hoenig/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/hoenig/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 286, in run_step
    losses.backward()
  File "/home/hoenig/.local/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/hoenig/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 23.67 GiB total capacity; 19.40 GiB already allocated; 66.69 MiB free; 20.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[10/11 07:00:13] d2.engine.hooks INFO: Overall training speed: 121 iterations in 0:01:58 (0.9829 s / it)
[10/11 07:00:13] d2.engine.hooks INFO: Total training time: 0:01:59 (0:00:00 on hooks)
[10/11 07:00:13] d2.utils.events INFO:  eta: 5 days, 17:40:40  iter: 123  total_loss: 4.28  loss_cls_stage0: 1.018  loss_box_reg_stage0: 0.6651  loss_cls_stage1: 0.5492  loss_box_reg_stage1: 0.3749  loss_cls_stage2: 0.318  loss_box_reg_stage2: 0.1259  loss_mask: 0.6921  loss_rpn_cls: 0.3461  loss_rpn_loc: 0.1685  time: 0.9793  data_time: 0.0050  lr: 1.069e-05  max_mem: 20031M
